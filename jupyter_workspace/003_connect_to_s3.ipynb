{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "#from pyspark.sql import SparkSession, DataFrame\n",
    "\n",
    "def main():\n",
    "    args = getResolvedOptions(sys.argv, [\"JOB_NAME\"])\n",
    "    sc = SparkContext()\n",
    "    glueContext = GlueContext(sc)\n",
    "    spark = glueContext.spark_session\n",
    "    # spark = SparkSession.builder.getOrCreate()\n",
    "    job = Job(glueContext)\n",
    "    logger = glueContext.get_logger()\n",
    "    job.init(args[\"JOB_NAME\"], args)\n",
    "\n",
    "    #print(\"Hello Glue!\")\n",
    "\n",
    "    file_name = \"s3://athena-examples-us-east-1/notebooks/yellow_tripdata_2016-01.parquet\"\n",
    "    glue_df = glueContext.create_dynamic_frame.from_options(\n",
    "                format_options={},\n",
    "                connection_type=\"s3\",\n",
    "                format=\"parquet\",\n",
    "                connection_options={\n",
    "                    \"paths\": [file_name],\n",
    "                    \"recurse\": True,\n",
    "                },\n",
    "            )\n",
    "    pandas_df = glue_df.toDF()\n",
    "    pandas_df.show(3)\n",
    "    job.commit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
